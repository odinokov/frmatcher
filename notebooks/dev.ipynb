{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../config/patterns.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../config/patterns.yaml\n",
    "patterns:\n",
    "  r1:\n",
    "    - \"_1\"\n",
    "    - \"_r1\"\n",
    "    - \"_R1\"\n",
    "    - \"_r\"\n",
    "    - \"_F\"\n",
    "  r2:\n",
    "    - \"_2\"\n",
    "    - \"_r2\"\n",
    "    - \"_R2\"\n",
    "    - \"_f\"\n",
    "    - \"_R\"\n",
    "  ignore:\n",
    "    - \"^i_\"\n",
    "    - \"^I_\"\n",
    "    - \"_i\\\\d+\"\n",
    "    - \"_I\\\\d+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ln -s ../config ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../frmatcher/fastq_file_name_checker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../frmatcher/fastq_file_name_checker.py\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "from typing import Dict, List, Optional\n",
    "from loguru import logger\n",
    "import importlib.resources as resources  # Modern resource handling for Python 3.7+\n",
    "\n",
    "class FilenameLengthMismatchError(ValueError):\n",
    "    \"\"\"Custom exception for filename length mismatches.\"\"\"\n",
    "\n",
    "class PatternsNotLoadedError(ValueError):\n",
    "    \"\"\"Custom exception when patterns are not loaded.\"\"\"\n",
    "\n",
    "class FastqFileNameChecker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        filenames: List[str],\n",
    "        config_path: Optional[str] = None,\n",
    "        length_check: bool = False,\n",
    "        verbose: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the FastqFileNameChecker with a list of filenames.\n",
    "\n",
    "        Args:\n",
    "            filenames (List[str]): List of file paths to categorize.\n",
    "            config_path (str, optional): Path to the YAML configuration file.\n",
    "                Defaults to None, and patterns must be manually injected.\n",
    "            length_check (bool): Whether to check if all filenames have the same length.\n",
    "                Default is False.\n",
    "            verbose (bool): Whether to enable detailed logging.\n",
    "                Default is False.\n",
    "\n",
    "        Raises:\n",
    "            FilenameLengthMismatchError: If filenames have different lengths and length_check is True.\n",
    "            FileNotFoundError: If the configuration file does not exist.\n",
    "            yaml.YAMLError: If the configuration file is invalid.\n",
    "        \"\"\"\n",
    "        self.filenames = filenames\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Configure logging\n",
    "        logger.remove()  # Remove the default handler\n",
    "        if self.verbose:\n",
    "            logger.add(lambda msg: print(msg, end=\"\"), level=\"DEBUG\", colorize=True)\n",
    "        else:\n",
    "            logger.add(lambda msg: print(msg, end=\"\"), level=\"ERROR\", colorize=True)\n",
    "\n",
    "        # Only load patterns from config if no patterns are directly injected\n",
    "        if config_path is None and not hasattr(self, \"patterns\"):\n",
    "            self.patterns = None  # Set patterns to None initially\n",
    "        elif config_path is not None:\n",
    "            self.patterns = self.load_patterns(config_path)\n",
    "\n",
    "        # Precompile regex patterns if patterns are loaded or injected\n",
    "        if self.patterns:\n",
    "            self.compiled_patterns = self.compile_patterns(self.patterns)\n",
    "\n",
    "        if length_check:\n",
    "            self._check_filename_lengths()\n",
    "\n",
    "    def load_patterns(self, config_path: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Load patterns from a YAML configuration file.\n",
    "\n",
    "        Args:\n",
    "            config_path (str): Path to the YAML configuration file.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: A dictionary with R1, R2, and ignore patterns.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the configuration file does not exist.\n",
    "            yaml.YAMLError: If the configuration file is invalid.\n",
    "        \"\"\"\n",
    "        if not os.path.isfile(config_path):\n",
    "            logger.error(f\"Configuration file not found at {config_path}\")\n",
    "            raise FileNotFoundError(f\"Configuration file not found at {config_path}\")\n",
    "\n",
    "        try:\n",
    "            with open(config_path, \"r\") as file:\n",
    "                config = yaml.safe_load(file)\n",
    "            return config[\"patterns\"]\n",
    "        except yaml.YAMLError as e:\n",
    "            logger.error(f\"Error parsing YAML configuration: {e}\")\n",
    "            raise\n",
    "\n",
    "    def compile_patterns(self, patterns: Dict[str, List[str]]) -> Dict[str, List[re.Pattern]]:\n",
    "        \"\"\"\n",
    "        Compile regex patterns for R1, R2, and ignore categories.\n",
    "\n",
    "        Args:\n",
    "            patterns (Dict[str, List[str]]): Raw patterns from configuration.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[re.Pattern]]: Compiled regex patterns.\n",
    "        \"\"\"\n",
    "        compiled = {\n",
    "            \"R1\": [re.compile(f\".*({pattern})([._-]).*\") for pattern in patterns.get(\"r1\", [])],\n",
    "            \"R2\": [re.compile(f\".*({pattern})([._-]).*\") for pattern in patterns.get(\"r2\", [])],\n",
    "            \"ignore\": [re.compile(f\".*({pattern}).*\") for pattern in patterns.get(\"ignore\", [])],\n",
    "        }\n",
    "        return compiled\n",
    "\n",
    "    def _check_filename_lengths(self) -> None:\n",
    "        \"\"\"\n",
    "        Checks if all filenames have the same length.\n",
    "\n",
    "        Raises:\n",
    "            FilenameLengthMismatchError: If filenames do not have the same length.\n",
    "        \"\"\"\n",
    "        lengths = list(map(len, self.filenames))\n",
    "        if len(set(lengths)) > 1:\n",
    "            logger.error(\"Filenames do not all have the same length. Please ensure all filenames are consistent.\")\n",
    "            raise FilenameLengthMismatchError(\"Filenames do not all have the same length. Please ensure all filenames are consistent.\")\n",
    "\n",
    "    def categorize_fastq_files(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Categorizes FASTQ files into R1, R2, or ignored based on filename patterns.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: A dictionary with keys 'R1', 'R2', and 'ignored',\n",
    "                each containing lists of full file paths.\n",
    "\n",
    "        Raises:\n",
    "            PatternsNotLoadedError: If regex patterns are not loaded.\n",
    "            FilenameLengthMismatchError: If the number of R1 and R2 files is unbalanced.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"compiled_patterns\"):\n",
    "            raise PatternsNotLoadedError(\"Patterns not loaded or compiled.\")\n",
    "\n",
    "        categorized_files: Dict[str, List[str]] = {\"R1\": [], \"R2\": [], \"ignored\": []}\n",
    "\n",
    "        for full_path in self.filenames:\n",
    "            filename = os.path.basename(full_path)\n",
    "            if any(pattern.search(filename) for pattern in self.compiled_patterns[\"ignore\"]):\n",
    "                categorized_files[\"ignored\"].append(full_path)\n",
    "            elif any(pattern.search(filename) for pattern in self.compiled_patterns[\"R1\"]):\n",
    "                categorized_files[\"R1\"].append(full_path)\n",
    "            elif any(pattern.search(filename) for pattern in self.compiled_patterns[\"R2\"]):\n",
    "                categorized_files[\"R2\"].append(full_path)\n",
    "            else:\n",
    "                categorized_files[\"ignored\"].append(full_path)\n",
    "\n",
    "        # Sort the filenames alphabetically in each category\n",
    "        for category in categorized_files:\n",
    "            categorized_files[category].sort()\n",
    "\n",
    "        # Check if the number of R1 and R2 files is balanced\n",
    "        len_r1 = len(categorized_files.get(\"R1\", []))\n",
    "        len_r2 = len(categorized_files.get(\"R2\", []))\n",
    "\n",
    "        if len_r1 != len_r2:\n",
    "            logger.error(f\"Unbalanced categories: R1={len_r1}, R2={len_r2}\")\n",
    "            raise FilenameLengthMismatchError(f\"Unbalanced categories: R1={len_r1}, R2={len_r2}\")\n",
    "\n",
    "        return categorized_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load  ../frmatcher/fastq_file_name_checker.py\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import yaml\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "class FilenameLengthMismatchError(ValueError):\n",
    "    \"\"\"Custom exception for filename length mismatches.\"\"\"\n",
    "\n",
    "\n",
    "class PatternsNotLoadedError(ValueError):\n",
    "    \"\"\"Custom exception when patterns are not loaded.\"\"\"\n",
    "\n",
    "\n",
    "class FastqFileNameChecker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        filenames: List[str],\n",
    "        config_path: Optional[str] = None,\n",
    "        length_check: bool = False,\n",
    "        verbose: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the FastqFileNameChecker with a list of filenames.\n",
    "\n",
    "        Args:\n",
    "            filenames (List[str]): List of file paths to categorize.\n",
    "            config_path (str, optional): Path to the YAML configuration file.\n",
    "                Defaults to None, and patterns must be manually injected.\n",
    "            length_check (bool): Whether to check if all filenames have the same length.\n",
    "                Default is False.\n",
    "            verbose (bool): Whether to enable detailed logging.\n",
    "                Default is False.\n",
    "\n",
    "        Raises:\n",
    "            FilenameLengthMismatchError: If filenames have different lengths and length_check is True.\n",
    "            FileNotFoundError: If the configuration file does not exist.\n",
    "            yaml.YAMLError: If the configuration file is invalid.\n",
    "        \"\"\"\n",
    "        self.filenames = filenames\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Configure logging\n",
    "        logger.remove()  # Remove the default handler\n",
    "        if self.verbose:\n",
    "            logger.add(lambda msg: print(msg, end=\"\"), level=\"DEBUG\", colorize=True)\n",
    "        else:\n",
    "            logger.add(lambda msg: print(msg, end=\"\"), level=\"ERROR\", colorize=True)\n",
    "\n",
    "        # Only load patterns from config if no patterns are directly injected\n",
    "        if config_path is None and not hasattr(self, \"patterns\"):\n",
    "            self.patterns = None  # Set patterns to None initially\n",
    "        elif config_path is not None:\n",
    "            self.patterns = self.load_patterns(config_path)\n",
    "\n",
    "        # Precompile regex patterns if patterns are loaded or injected\n",
    "        if self.patterns:\n",
    "            self.compiled_patterns = self.compile_patterns(self.patterns)\n",
    "\n",
    "        if length_check:\n",
    "            self._check_filename_lengths()\n",
    "\n",
    "    def load_patterns(self, config_path: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Load patterns from a YAML configuration file.\n",
    "\n",
    "        Args:\n",
    "            config_path (str): Path to the YAML configuration file.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: A dictionary with R1, R2, and ignore patterns.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the configuration file does not exist.\n",
    "            yaml.YAMLError: If the configuration file is invalid.\n",
    "        \"\"\"\n",
    "        if not os.path.isfile(config_path):\n",
    "            logger.error(f\"Configuration file not found at {config_path}\")\n",
    "            raise FileNotFoundError(f\"Configuration file not found at {config_path}\")\n",
    "\n",
    "        try:\n",
    "            with open(config_path, \"r\") as file:\n",
    "                config = yaml.safe_load(file)\n",
    "            return config[\"patterns\"]\n",
    "        except yaml.YAMLError as e:\n",
    "            logger.error(f\"Error parsing YAML configuration: {e}\")\n",
    "            raise\n",
    "\n",
    "    def compile_patterns(\n",
    "        self, patterns: Dict[str, List[str]]\n",
    "    ) -> Dict[str, List[re.Pattern]]:\n",
    "        \"\"\"\n",
    "        Compile regex patterns for R1, R2, and ignore categories.\n",
    "\n",
    "        Args:\n",
    "            patterns (Dict[str, List[str]]): Raw patterns from configuration.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[re.Pattern]]: Compiled regex patterns.\n",
    "        \"\"\"\n",
    "        compiled = {\n",
    "            \"R1\": [\n",
    "                re.compile(f\".*({pattern})([._-]).*\")\n",
    "                for pattern in patterns.get(\"r1\", [])\n",
    "            ],\n",
    "            \"R2\": [\n",
    "                re.compile(f\".*({pattern})([._-]).*\")\n",
    "                for pattern in patterns.get(\"r2\", [])\n",
    "            ],\n",
    "            \"ignore\": [\n",
    "                re.compile(f\".*({pattern}).*\") for pattern in patterns.get(\"ignore\", [])\n",
    "            ],\n",
    "        }\n",
    "        return compiled\n",
    "\n",
    "    def _check_filename_lengths(self) -> None:\n",
    "        \"\"\"\n",
    "        Checks if all filenames have the same length.\n",
    "\n",
    "        Raises:\n",
    "            FilenameLengthMismatchError: If filenames do not have the same length.\n",
    "        \"\"\"\n",
    "        lengths = list(map(len, self.filenames))\n",
    "        if len(set(lengths)) > 1:\n",
    "            logger.error(\n",
    "                \"Filenames do not all have the same length. Please ensure all filenames are consistent.\"\n",
    "            )\n",
    "            raise FilenameLengthMismatchError(\n",
    "                \"Filenames do not all have the same length. Please ensure all filenames are consistent.\"\n",
    "            )\n",
    "\n",
    "    def categorize_fastq_files(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Categorizes FASTQ files into R1, R2, or ignored based on filename patterns.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: A dictionary with keys 'R1', 'R2', and 'ignored',\n",
    "                each containing lists of full file paths.\n",
    "\n",
    "        Raises:\n",
    "            PatternsNotLoadedError: If regex patterns are not loaded.\n",
    "            FilenameLengthMismatchError: If the number of R1 and R2 files is unbalanced.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"compiled_patterns\"):\n",
    "            raise PatternsNotLoadedError(\"Patterns not loaded or compiled.\")\n",
    "\n",
    "        categorized_files: Dict[str, List[str]] = {\"R1\": [], \"R2\": [], \"ignored\": []}\n",
    "\n",
    "        for full_path in self.filenames:\n",
    "            filename = os.path.basename(full_path)\n",
    "            if any(\n",
    "                pattern.search(filename) for pattern in self.compiled_patterns[\"ignore\"]\n",
    "            ):\n",
    "                categorized_files[\"ignored\"].append(full_path)\n",
    "            elif any(\n",
    "                pattern.search(filename) for pattern in self.compiled_patterns[\"R1\"]\n",
    "            ):\n",
    "                categorized_files[\"R1\"].append(full_path)\n",
    "            elif any(\n",
    "                pattern.search(filename) for pattern in self.compiled_patterns[\"R2\"]\n",
    "            ):\n",
    "                categorized_files[\"R2\"].append(full_path)\n",
    "            else:\n",
    "                categorized_files[\"ignored\"].append(full_path)\n",
    "\n",
    "        # Sort the filenames alphabetically in each category\n",
    "        for category in categorized_files:\n",
    "            categorized_files[category].sort()\n",
    "\n",
    "        # Check if the number of R1 and R2 files is balanced\n",
    "        len_r1 = len(categorized_files.get(\"R1\", []))\n",
    "        len_r2 = len(categorized_files.get(\"R2\", []))\n",
    "\n",
    "        if len_r1 != len_r2:\n",
    "            logger.error(f\"Unbalanced categories: R1={len_r1}, R2={len_r2}\")\n",
    "            raise FilenameLengthMismatchError(\n",
    "                f\"Unbalanced categories: R1={len_r1}, R2={len_r2}\"\n",
    "            )\n",
    "\n",
    "        return categorized_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-27 22:53:44.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mR1:\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - ./_1/sample_F_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - ./_1/sample_F_L011.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mR2:\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - ./_1/sample_R_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - ./_1/sample_R_L011.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mignored:\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - I_sample_2_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - i_sample_1_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - sample_A_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-09-27 22:53:44.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - sample_B_L001.fastq.gz\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R1': ['./_1/sample_F_L001.fastq.gz', './_1/sample_F_L011.fastq.gz'],\n",
       " 'R2': ['./_1/sample_R_L001.fastq.gz', './_1/sample_R_L011.fastq.gz'],\n",
       " 'ignored': ['I_sample_2_L001.fastq.gz',\n",
       "  'i_sample_1_L001.fastq.gz',\n",
       "  'sample_A_L001.fastq.gz',\n",
       "  'sample_B_L001.fastq.gz']}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample usage\n",
    "filenames = [\n",
    "    \"./_1/sample_R_L001.fastq.gz\",  # R1 with lane info\n",
    "    \"./_1/sample_F_L001.fastq.gz\",  # R2 with lane info\n",
    "    \"./_1/sample_R_L011.fastq.gz\",  # R1 with lane info\n",
    "    \"./_1/sample_F_L011.fastq.gz\",  # R2 with lane info\n",
    "    # \"sample_2_L011.fastq.gz\",  # R2 with lane info\n",
    "    \"i_sample_1_L001.fastq.gz\",  # Ignored due to prefix \"i_\"\n",
    "    \"I_sample_2_L001.fastq.gz\",  # Ignored due to prefix \"I_\"\n",
    "    #     \"sample_r1_i1.fastq.gz\",   # Ignored due to multiplex index\n",
    "    \"sample_A_L001.fastq.gz\",  # R1 with lane info\n",
    "    \"sample_B_L001.fastq.gz\",  # R2 with lane info\n",
    "]\n",
    "\n",
    "try:\n",
    "    checker = FastqFileNameChecker(\n",
    "        filenames,\n",
    "        length_check=False,\n",
    "        verbose=True,\n",
    "        config_path=\"../frmatcher/config/patterns.yaml\",\n",
    "    )\n",
    "    categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "    # Output the categorized files\n",
    "    for category, files in categorized_files.items():\n",
    "        logger.info(f\"{category}:\")\n",
    "        for file in files:\n",
    "            logger.info(f\"  - {file}\")\n",
    "except ValueError as e:\n",
    "    logger.error(str(e))\n",
    "\n",
    "categorized_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
      "\n",
      "No dependencies to install or update\n",
      "\n",
      "\u001b[39;1mInstalling\u001b[39;22m the current project: \u001b[36mfrmatcher\u001b[39m (\u001b[39;1m0.2.0\u001b[39;22m)\u001b[1G\u001b[2K\u001b[39;1mInstalling\u001b[39;22m the current project: \u001b[36mfrmatcher\u001b[39m (\u001b[32m0.2.0\u001b[39m)\n"
     ]
    }
   ],
   "source": [
    "! poetry install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], 'ignored': []}\n"
     ]
    }
   ],
   "source": [
    "from frmatcher import FastqFileNameChecker\n",
    "\n",
    "filenames = [\n",
    "    \"sample_1_L001.fastq.gz\",\n",
    "    \"sample_2_L001.fastq.gz\",\n",
    "    \"sample_1_L002.fastq.gz\",\n",
    "    \"sample_2_L002.fastq.gz\",\n",
    "]\n",
    "\n",
    "checker = FastqFileNameChecker(filenames, length_check=False, verbose=False)\n",
    "\n",
    "# checker = FastqFileNameChecker(filenames,\n",
    "#                                length_check=True,\n",
    "#                                verbose=True,\n",
    "#                                config_path=None)\n",
    "# checker.patterns = {\n",
    "#     'r1': [\"_1\", \"_R1\"],\n",
    "#     'r2': [\"_2\", \"_R2\"],\n",
    "#     'ignore': [\"^i_\", \"^I_\", \"_i\\\\d+\", \"_I\\\\d+\"]\n",
    "# }\n",
    "\n",
    "categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "print(categorized_files)\n",
    "\n",
    "# {'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'],\n",
    "# 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'],\n",
    "# 'ignored': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], 'ignored': []}\n"
     ]
    }
   ],
   "source": [
    "from frmatcher import FastqFileNameChecker\n",
    "\n",
    "filenames = [\n",
    "    \"sample_1_L001.fastq.gz\",\n",
    "    \"sample_2_L001.fastq.gz\",\n",
    "    \"sample_1_L002.fastq.gz\",\n",
    "    \"sample_2_L002.fastq.gz\",\n",
    "]\n",
    "\n",
    "\n",
    "checker = FastqFileNameChecker(\n",
    "    filenames, length_check=True, verbose=False, config_path=None\n",
    ")\n",
    "checker.patterns = {\n",
    "    \"r1\": [\"_1\", \"_R1\"],\n",
    "    \"r2\": [\"_2\", \"_R2\"],\n",
    "    \"ignore\": [\"^i_\", \"^I_\", \"_i\\\\d+\", \"_I\\\\d+\"],\n",
    "}\n",
    "\n",
    "categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "print(categorized_files)\n",
    "\n",
    "# {'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'],\n",
    "# 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'],\n",
    "# 'ignored': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../tests/test_fastq_file_name_checker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../tests/test_fastq_file_name_checker.py\n",
    "import unittest\n",
    "import yaml\n",
    "# Adjust the import according to your module structure\n",
    "from frmatcher import FastqFileNameChecker\n",
    "\n",
    "class TestFastqFileNameChecker(unittest.TestCase):\n",
    "\n",
    "    def test_categorization(self):\n",
    "        # Define the YAML patterns directly in the test\n",
    "        patterns = yaml.safe_load(r\"\"\"\n",
    "        patterns:\n",
    "          r1:\n",
    "            - \"_1\"\n",
    "            - \"_R1\"\n",
    "          r2:\n",
    "            - \"_2\"\n",
    "            - \"_R2\"\n",
    "          ignore:\n",
    "            - \"^i_\"\n",
    "            - \"^I_\"\n",
    "            - \"_i\\\\d+\"\n",
    "            - \"_I\\\\d+\"\n",
    "        \"\"\")\n",
    "\n",
    "        filenames = [\n",
    "            \"sample_1_L001.fastq.gz\",    # R1\n",
    "            \"sample_R1_L001.fastq.gz\",   # R1\n",
    "            \"sample_2_L001.fastq.gz\",    # R2\n",
    "            \"sample_R2_L001.fastq.gz\",   # R2\n",
    "            \"sample_i1_L001.fastq.gz\",   # Ignored\n",
    "            \"sample_I2_L001.fastq.gz\",   # Ignored\n",
    "            \"i_sample_1_L001.fastq.gz\",  # Ignored\n",
    "            \"I_sample_2_L001.fastq.gz\",  # Ignored\n",
    "            \"sample_A_L001.fastq.gz\"     # Ignored (no matching pattern)\n",
    "        ]\n",
    "\n",
    "        # Initialize checker without config_path, since we're injecting the patterns directly\n",
    "        checker = FastqFileNameChecker(filenames)\n",
    "        checker.patterns = patterns['patterns']  # Inject the test patterns directly\n",
    "        checker.compiled_patterns = checker.compile_patterns(checker.patterns)  # Compile patterns after injection\n",
    "\n",
    "        categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "        # Assert correct categorization\n",
    "        expected_r1 = {\"sample_1_L001.fastq.gz\", \"sample_R1_L001.fastq.gz\"}\n",
    "        expected_r2 = {\"sample_2_L001.fastq.gz\", \"sample_R2_L001.fastq.gz\"}\n",
    "        expected_ignored = {\n",
    "            \"sample_i1_L001.fastq.gz\",\n",
    "            \"sample_I2_L001.fastq.gz\",\n",
    "            \"i_sample_1_L001.fastq.gz\",\n",
    "            \"I_sample_2_L001.fastq.gz\",\n",
    "            \"sample_A_L001.fastq.gz\"\n",
    "        }\n",
    "\n",
    "        with self.subTest(\"R1 Categorization\"):\n",
    "            self.assertEqual(set(categorized_files['R1']), expected_r1)\n",
    "\n",
    "        with self.subTest(\"R2 Categorization\"):\n",
    "            self.assertEqual(set(categorized_files['R2']), expected_r2)\n",
    "\n",
    "        with self.subTest(\"Ignored Categorization\"):\n",
    "            self.assertEqual(set(categorized_files['ignored']), expected_ignored)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../.gitignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../.gitignore\n",
    "# Byte-compiled / optimized / DLL files\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*$py.class\n",
    "\n",
    "# C extensions\n",
    "*.so\n",
    "\n",
    "# Distribution / packaging\n",
    ".Python\n",
    "env/\n",
    "venv/\n",
    "ENV/\n",
    "build/\n",
    "develop-eggs/\n",
    "dist/\n",
    "downloads/\n",
    "eggs/\n",
    ".eggs/\n",
    "lib/\n",
    "lib64/\n",
    "parts/\n",
    "sdist/\n",
    "var/\n",
    "wheels/\n",
    "*.egg-info/\n",
    ".installed.cfg\n",
    "*.egg\n",
    "MANIFEST\n",
    "\n",
    "# Installer logs\n",
    "pip-log.txt\n",
    "pip-delete-this-directory.txt\n",
    "\n",
    "# Unit test / coverage reports\n",
    "htmlcov/\n",
    ".tox/\n",
    ".nox/\n",
    "coverage.xml\n",
    "*.cover\n",
    "*.py,cover\n",
    ".hypothesis/\n",
    ".pytest_cache/\n",
    "cover/\n",
    "\n",
    "# mypy\n",
    ".mypy_cache/\n",
    ".dmypy.json\n",
    "dmypy.json\n",
    "\n",
    "# Pyre type checker\n",
    ".pyre/\n",
    "\n",
    "# Environments\n",
    ".env\n",
    ".envrc\n",
    "venv/\n",
    ".venv/\n",
    "\n",
    "# Poetry-specific files\n",
    "poetry.lock\n",
    "# If you use pyproject.toml for other purposes, uncomment the line below\n",
    "# !pyproject.toml\n",
    "\n",
    "# VS Code settings\n",
    ".vscode/\n",
    "\n",
    "# MacOS files\n",
    ".DS_Store\n",
    "\n",
    "# PyCharm settings\n",
    ".idea/\n",
    "\n",
    "# Local config files\n",
    "*.local\n",
    "*.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../LICENSE\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../LICENSE\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2024 Denis Odinokov\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], 'ignored': []}\n"
     ]
    }
   ],
   "source": [
    "from frmatcher.fastq_file_name_checker import FastqFileNameChecker\n",
    "\n",
    "filenames = [\n",
    "    \"sample_1_L001.fastq.gz\",\n",
    "    \"sample_2_L001.fastq.gz\",\n",
    "    \"sample_1_L002.fastq.gz\",\n",
    "    \"sample_2_L002.fastq.gz\",\n",
    "]\n",
    "\n",
    "checker = FastqFileNameChecker(\n",
    "    filenames, length_check=False, verbose=False, config_path=None\n",
    ")\n",
    "checker.patterns = {\n",
    "    \"r1\": [\"_1\", \"_R1\"],\n",
    "    \"r2\": [\"_2\", \"_R2\"],\n",
    "    \"ignore\": [\"^i_\", \"^I_\", \"_i\\\\d+\", \"_I\\\\d+\"],\n",
    "}\n",
    "categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "print(categorized_files)\n",
    "# {'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], 'ignored': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../README.md\n",
    "# FRMatcher\n",
    "\n",
    "**FRMatcher** categorizes a list of presumably FASTQ files into `R1` (forward reads) and `R2` (reverse reads) pairs using customizable pattern matching.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Clone the repository:\n",
    "   ```bash\n",
    "   git clone https://github.com/odinokov/frmatcher.git\n",
    "   cd frmatcher\n",
    "   ```\n",
    "\n",
    "Activate the virtual environment:\n",
    "   ```bash\n",
    "   poetry shell\n",
    "   ```\n",
    "\n",
    "Build the package:\n",
    "   ```bash\n",
    "   poetry build\n",
    "   ```\n",
    "\n",
    "Install the package locally:\n",
    "   ```bash\n",
    "   poetry install\n",
    "   ```\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from frmatcher.fastq_file_name_checker import FastqFileNameChecker\n",
    "\n",
    "filenames = [\n",
    "    \"sample_1_L001.fastq.gz\",\n",
    "    \"sample_2_L001.fastq.gz\",\n",
    "    \"sample_1_L002.fastq.gz\",\n",
    "    \"sample_2_L002.fastq.gz\",\n",
    "]\n",
    "\n",
    "checker = FastqFileNameChecker(filenames,\n",
    "                              length_check=False,\n",
    "                              verbose=False)\n",
    "\n",
    "# checker = FastqFileNameChecker(filenames,\n",
    "#                                length_check=True,\n",
    "#                                verbose=True,\n",
    "#                                config_path=None)\n",
    "# checker.patterns = {\n",
    "#     'r1': [\"_1\", \"_R1\"],\n",
    "#     'r2': [\"_2\", \"_R2\"],\n",
    "#     'ignore': [\"^i_\", \"^I_\", \"_i\\\\d+\", \"_I\\\\d+\"]\n",
    "# }\n",
    "\n",
    "categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "print(categorized_files)\n",
    "\n",
    "# {'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], \n",
    "# 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], \n",
    "# 'ignored': []}\n",
    "\n",
    "```\n",
    "\n",
    "## License\n",
    "\n",
    "MIT License. See the [LICENSE](LICENSE) file for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../config/patterns.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../config/patterns.yaml\n",
    "patterns:\n",
    "  r1:\n",
    "    - \"_1\"\n",
    "    - \"_r1\"\n",
    "    - \"_R1\"\n",
    "    - \"_r\"\n",
    "    - \"_F\"\n",
    "  r2:\n",
    "    - \"_2\"\n",
    "    - \"_r2\"\n",
    "    - \"_R2\"\n",
    "    - \"_f\"\n",
    "    - \"_R\"\n",
    "  ignore:\n",
    "    - \"^i_\"\n",
    "    - \"^I_\"\n",
    "    - \"_i\\\\d+\"\n",
    "    - \"_I\\\\d+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ln -s ../config ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20218/554114187.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# %load  ../frmatcher/fastq_file_name_checker.py\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "import pkg_resources\n",
    "import yaml\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "class FastqFileNameChecker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        filenames: List[str],\n",
    "        config_path: str = None,\n",
    "        length_check: bool = False,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the FastqFileNameChecker with a list of filenames.\n",
    "\n",
    "        Args:\n",
    "            filenames (List[str]): List of filenames to categorize.\n",
    "            config_path (str): Path to the YAML configuration file. Default loads from package if None.\n",
    "            length_check (bool): Whether to check if all filenames have the same length. Default is False.\n",
    "            verbose (bool): Whether to enable detailed logging. Default is False.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If filenames have different lengths and length_check is True.\n",
    "        \"\"\"\n",
    "        self.filenames = filenames\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Set logging level based on verbosity\n",
    "        logger.remove()  # Remove the default handler\n",
    "        if self.verbose:\n",
    "            logger.add(lambda msg: print(msg, end=\"\"), level=\"DEBUG\", colorize=True)\n",
    "        else:\n",
    "            logger.add(lambda msg: print(msg, end=\"\"), level=\"ERROR\", colorize=True)\n",
    "\n",
    "        # Load patterns from the package if no config_path is provided\n",
    "        if config_path is None:\n",
    "            config_path = pkg_resources.resource_filename(\n",
    "                __name__, \"config/patterns.yaml\"\n",
    "            )\n",
    "        self.patterns = self.load_patterns(config_path)\n",
    "\n",
    "        if length_check:\n",
    "            self._check_filename_lengths()\n",
    "\n",
    "    def load_patterns(self, config_path: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Load patterns from a YAML configuration file.\n",
    "\n",
    "        Args:\n",
    "            config_path (str): Path to the YAML configuration file.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: A dictionary with R1, R2, and ignore patterns.\n",
    "        \"\"\"\n",
    "        with open(config_path, \"r\") as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        logger.debug(f\"Loaded patterns from {config_path}\")\n",
    "        return config[\"patterns\"]\n",
    "\n",
    "    def _check_filename_lengths(self) -> None:\n",
    "        \"\"\"\n",
    "        Checks if all filenames have the same length.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If filenames do not have the same length.\n",
    "        \"\"\"\n",
    "        lengths = list(map(len, self.filenames))\n",
    "        if len(set(lengths)) > 1:\n",
    "            logger.error(\n",
    "                \"Filenames do not all have the same length. Please ensure all filenames are consistent.\"\n",
    "            )\n",
    "            raise ValueError(\n",
    "                \"Filenames do not all have the same length. Please ensure all filenames are consistent.\"\n",
    "            )\n",
    "        logger.info(\"All filenames have the same length.\")\n",
    "\n",
    "    def categorize_fastq_files(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Categorizes FASTQ files into R1, R2, or ignored based on filename patterns.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: A dictionary with keys 'R1', 'R2', and 'ignored', each containing lists of filenames.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"patterns\"):\n",
    "            raise ValueError(\n",
    "                \"No patterns loaded. Either provide a config_path or manually inject patterns.\"\n",
    "            )\n",
    "\n",
    "        # Compile regex patterns from the YAML configuration\n",
    "        r1_patterns = [\n",
    "            re.compile(f\".*({pattern})(\\.|\\_|\\-).*\") for pattern in self.patterns[\"r1\"]\n",
    "        ]\n",
    "        r2_patterns = [\n",
    "            re.compile(f\".*({pattern})(\\.|\\_|\\-).*\") for pattern in self.patterns[\"r2\"]\n",
    "        ]\n",
    "        ignore_patterns = [\n",
    "            re.compile(f\".*({pattern}).*\") for pattern in self.patterns[\"ignore\"]\n",
    "        ]\n",
    "\n",
    "        # Initialize the result dictionary\n",
    "        categorized_files = {\"R1\": [], \"R2\": [], \"ignored\": []}\n",
    "\n",
    "        # Categorize each file\n",
    "        for filename in self.filenames:\n",
    "            if any(pattern.search(filename) for pattern in ignore_patterns):\n",
    "                categorized_files[\"ignored\"].append(filename)\n",
    "                logger.debug(f\"Ignored file: {filename}\")\n",
    "            elif any(pattern.search(filename) for pattern in r1_patterns):\n",
    "                categorized_files[\"R1\"].append(filename)\n",
    "                logger.debug(f\"Categorized as R1: {filename}\")\n",
    "            elif any(pattern.search(filename) for pattern in r2_patterns):\n",
    "                categorized_files[\"R2\"].append(filename)\n",
    "                logger.debug(f\"Categorized as R2: {filename}\")\n",
    "            else:\n",
    "                # If it doesn't match any of the patterns, categorize as ignored\n",
    "                categorized_files[\"ignored\"].append(filename)\n",
    "                logger.debug(\n",
    "                    f\"File did not match any R1 or R2 patterns. Index file? {filename}\"\n",
    "                )\n",
    "\n",
    "        # Sort the filenames alphabetically in each category\n",
    "        for category in categorized_files:\n",
    "            categorized_files[category].sort()\n",
    "\n",
    "        # Check if the number of R1 and R2 files is balanced\n",
    "        len_r1 = len(categorized_files.get(\"R1\", []))\n",
    "        len_r2 = len(categorized_files.get(\"R2\", []))\n",
    "\n",
    "        if len_r1 != len_r2:\n",
    "            logger.error(f\"Unbalanced categories: R1={len_r1}, R2={len_r2}\")\n",
    "            raise ValueError(f\"Unbalanced categories: R1={len_r1}, R2={len_r2}\")\n",
    "\n",
    "        return categorized_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-21 16:16:11.437\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_patterns\u001b[0m:\u001b[36m62\u001b[0m - \u001b[34m\u001b[1mLoaded patterns from ../frmatcher/config/patterns.yaml\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.438\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcategorize_fastq_files\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mCategorized as R2: sample_R_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcategorize_fastq_files\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mCategorized as R1: sample_F_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcategorize_fastq_files\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mCategorized as R2: sample_R_L011.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcategorize_fastq_files\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mCategorized as R1: sample_F_L011.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcategorize_fastq_files\u001b[0m:\u001b[36m112\u001b[0m - \u001b[34m\u001b[1mIgnored file: i_sample_1_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcategorize_fastq_files\u001b[0m:\u001b[36m112\u001b[0m - \u001b[34m\u001b[1mIgnored file: I_sample_2_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mR1:\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - sample_F_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - sample_F_L011.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mR2:\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - sample_R_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - sample_R_L011.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mignored:\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - I_sample_2_L001.fastq.gz\u001b[0m\n",
      "\u001b[32m2024-08-21 16:16:11.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1m  - i_sample_1_L001.fastq.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sample usage\n",
    "filenames = [\n",
    "    \"sample_R_L001.fastq.gz\",  # R1 with lane info\n",
    "    \"sample_F_L001.fastq.gz\",  # R2 with lane info\n",
    "    \"sample_R_L011.fastq.gz\",  # R1 with lane info\n",
    "    \"sample_F_L011.fastq.gz\",  # R2 with lane info\n",
    "    # \"sample_2_L011.fastq.gz\",  # R2 with lane info\n",
    "    \"i_sample_1_L001.fastq.gz\",  # Ignored due to prefix \"i_\"\n",
    "    \"I_sample_2_L001.fastq.gz\",  # Ignored due to prefix \"I_\"\n",
    "    #     \"sample_r1_i1.fastq.gz\",   # Ignored due to multiplex index\n",
    "    #     \"sample_A_L001.fastq.gz\",  # R1 with lane info\n",
    "    #     \"sample_B_L001.fastq.gz\",  # R2 with lane info\n",
    "]\n",
    "\n",
    "try:\n",
    "    checker = FastqFileNameChecker(\n",
    "        filenames,\n",
    "        length_check=False,\n",
    "        verbose=True,\n",
    "        config_path=\"../frmatcher/config/patterns.yaml\",\n",
    "    )\n",
    "    categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "    # Output the categorized files\n",
    "    for category, files in categorized_files.items():\n",
    "        logger.info(f\"{category}:\")\n",
    "        for file in files:\n",
    "            logger.info(f\"  - {file}\")\n",
    "except ValueError as e:\n",
    "    logger.error(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R1': ['sample_F_L001.fastq.gz', 'sample_F_L011.fastq.gz'],\n",
       " 'R2': ['sample_R_L001.fastq.gz', 'sample_R_L011.fastq.gz'],\n",
       " 'ignored': ['I_sample_2_L001.fastq.gz', 'i_sample_1_L001.fastq.gz']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorized_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../tests/test_fastq_file_name_checker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../tests/test_fastq_file_name_checker.py\n",
    "import unittest\n",
    "import yaml\n",
    "# Adjust the import according to your module structure\n",
    "from frmatcher.fastq_file_name_checker import FastqFileNameChecker\n",
    "\n",
    "class TestFastqFileNameChecker(unittest.TestCase):\n",
    "\n",
    "    def test_categorization(self):\n",
    "        # Define the YAML patterns directly in the test\n",
    "        patterns = yaml.safe_load(r\"\"\"\n",
    "        patterns:\n",
    "          r1:\n",
    "            - \"_1\"\n",
    "            - \"_R1\"\n",
    "          r2:\n",
    "            - \"_2\"\n",
    "            - \"_R2\"\n",
    "          ignore:\n",
    "            - \"^i_\"\n",
    "            - \"^I_\"\n",
    "            - \"_i\\\\d+\"\n",
    "            - \"_I\\\\d+\"\n",
    "        \"\"\")\n",
    "\n",
    "        filenames = [\n",
    "            \"sample_1_L001.fastq.gz\",    # R1\n",
    "            \"sample_R1_L001.fastq.gz\",   # R1\n",
    "            \"sample_2_L001.fastq.gz\",    # R2\n",
    "            \"sample_R2_L001.fastq.gz\",   # R2\n",
    "            \"sample_i1_L001.fastq.gz\",   # Ignored\n",
    "            \"sample_I2_L001.fastq.gz\",   # Ignored\n",
    "            \"i_sample_1_L001.fastq.gz\",  # Ignored\n",
    "            \"I_sample_2_L001.fastq.gz\",  # Ignored\n",
    "            \"sample_A_L001.fastq.gz\"     # Ignored (no matching pattern)\n",
    "        ]\n",
    "\n",
    "        # Initialize checker with in-memory patterns\n",
    "        checker = FastqFileNameChecker(filenames, config_path=None)\n",
    "        checker.patterns = patterns['patterns']  # Inject the test patterns directly\n",
    "        categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "        # Assert correct categorization\n",
    "        expected_r1 = {\"sample_1_L001.fastq.gz\", \"sample_R1_L001.fastq.gz\"}\n",
    "        expected_r2 = {\"sample_2_L001.fastq.gz\", \"sample_R2_L001.fastq.gz\"}\n",
    "        expected_ignored = {\n",
    "            \"sample_i1_L001.fastq.gz\",\n",
    "            \"sample_I2_L001.fastq.gz\",\n",
    "            \"i_sample_1_L001.fastq.gz\",\n",
    "            \"I_sample_2_L001.fastq.gz\",\n",
    "            \"sample_A_L001.fastq.gz\"\n",
    "        }\n",
    "\n",
    "        with self.subTest(\"R1 Categorization\"):\n",
    "            self.assertEqual(set(categorized_files['R1']), expected_r1)\n",
    "\n",
    "        with self.subTest(\"R2 Categorization\"):\n",
    "            self.assertEqual(set(categorized_files['R2']), expected_r2)\n",
    "\n",
    "        with self.subTest(\"Ignored Categorization\"):\n",
    "            self.assertEqual(set(categorized_files['ignored']), expected_ignored)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../.gitignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../.gitignore\n",
    "# Byte-compiled / optimized / DLL files\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*$py.class\n",
    "\n",
    "# C extensions\n",
    "*.so\n",
    "\n",
    "# Distribution / packaging\n",
    ".Python\n",
    "env/\n",
    "venv/\n",
    "ENV/\n",
    "build/\n",
    "develop-eggs/\n",
    "dist/\n",
    "downloads/\n",
    "eggs/\n",
    ".eggs/\n",
    "lib/\n",
    "lib64/\n",
    "parts/\n",
    "sdist/\n",
    "var/\n",
    "wheels/\n",
    "*.egg-info/\n",
    ".installed.cfg\n",
    "*.egg\n",
    "MANIFEST\n",
    "\n",
    "# Installer logs\n",
    "pip-log.txt\n",
    "pip-delete-this-directory.txt\n",
    "\n",
    "# Unit test / coverage reports\n",
    "htmlcov/\n",
    ".tox/\n",
    ".nox/\n",
    "coverage.xml\n",
    "*.cover\n",
    "*.py,cover\n",
    ".hypothesis/\n",
    ".pytest_cache/\n",
    "cover/\n",
    "\n",
    "# mypy\n",
    ".mypy_cache/\n",
    ".dmypy.json\n",
    "dmypy.json\n",
    "\n",
    "# Pyre type checker\n",
    ".pyre/\n",
    "\n",
    "# Environments\n",
    ".env\n",
    ".envrc\n",
    "venv/\n",
    ".venv/\n",
    "\n",
    "# Poetry-specific files\n",
    "poetry.lock\n",
    "# If you use pyproject.toml for other purposes, uncomment the line below\n",
    "# !pyproject.toml\n",
    "\n",
    "# VS Code settings\n",
    ".vscode/\n",
    "\n",
    "# MacOS files\n",
    ".DS_Store\n",
    "\n",
    "# PyCharm settings\n",
    ".idea/\n",
    "\n",
    "# Local config files\n",
    "*.local\n",
    "*.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../LICENSE\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../LICENSE\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2024 odinokov\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], 'ignored': []}\n"
     ]
    }
   ],
   "source": [
    "from frmatcher.fastq_file_name_checker import FastqFileNameChecker\n",
    "\n",
    "filenames = [\n",
    "    \"sample_1_L001.fastq.gz\",\n",
    "    \"sample_2_L001.fastq.gz\",\n",
    "    \"sample_1_L002.fastq.gz\",\n",
    "    \"sample_2_L002.fastq.gz\",\n",
    "]\n",
    "\n",
    "checker = FastqFileNameChecker(\n",
    "    filenames, length_check=False, verbose=False, config_path=None\n",
    ")\n",
    "checker.patterns = {\n",
    "    \"r1\": [\"_1\", \"_R1\"],\n",
    "    \"r2\": [\"_2\", \"_R2\"],\n",
    "    \"ignore\": [\"^i_\", \"^I_\", \"_i\\\\d+\", \"_I\\\\d+\"],\n",
    "}\n",
    "categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "print(categorized_files)\n",
    "# {'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], 'ignored': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../README.md\n",
    "# FRMatcher\n",
    "\n",
    "**FRMatcher** categorizes a list of presumably FASTQ files into `R1` (forward reads) and `R2` (reverse reads) pairs using customizable pattern matching.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Clone the repository:\n",
    "   ```bash\n",
    "   git clone https://github.com/odinokov/frmatcher.git\n",
    "   cd frmatcher\n",
    "   ```\n",
    "\n",
    "Activate the virtual environment:\n",
    "   ```bash\n",
    "   poetry shell\n",
    "   ```\n",
    "\n",
    "Build the package:\n",
    "   ```bash\n",
    "   poetry build\n",
    "   ```\n",
    "\n",
    "Install the package locally:\n",
    "   ```bash\n",
    "   poetry install\n",
    "   ```\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from frmatcher.fastq_file_name_checker import FastqFileNameChecker\n",
    "\n",
    "filenames = [\n",
    "    \"sample_1_L001.fastq.gz\",\n",
    "    \"sample_2_L001.fastq.gz\",\n",
    "    \"sample_1_L002.fastq.gz\",\n",
    "    \"sample_2_L002.fastq.gz\",\n",
    "]\n",
    "\n",
    "checker = FastqFileNameChecker(filenames,\n",
    "                              length_check=False,\n",
    "                              verbose=False)\n",
    "\n",
    "# checker = FastqFileNameChecker(filenames,\n",
    "#                                length_check=True,\n",
    "#                                verbose=True,\n",
    "#                                config_path=None)\n",
    "# checker.patterns = {\n",
    "#     'r1': [\"_1\", \"_R1\"],\n",
    "#     'r2': [\"_2\", \"_R2\"],\n",
    "#     'ignore': [\"^i_\", \"^I_\", \"_i\\\\d+\", \"_I\\\\d+\"]\n",
    "# }\n",
    "\n",
    "categorized_files = checker.categorize_fastq_files()\n",
    "\n",
    "print(categorized_files)\n",
    "\n",
    "# {'R1': ['sample_1_L001.fastq.gz', 'sample_1_L002.fastq.gz'], \n",
    "# 'R2': ['sample_2_L001.fastq.gz', 'sample_2_L002.fastq.gz'], \n",
    "# 'ignored': []}\n",
    "\n",
    "```\n",
    "\n",
    "## License\n",
    "\n",
    "MIT License. See the [LICENSE](LICENSE) file for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
